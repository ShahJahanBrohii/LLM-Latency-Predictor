# LLM-Latency-Predictor
A predictive modeling framework using Ridge Regression to estimate per-token inference latency in Large Language Models (Mistral-7B) based on prompt-level features and context size.
